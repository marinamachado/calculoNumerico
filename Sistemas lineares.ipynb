{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import solve_triangular\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposição LU\n",
    "\n",
    "Dado um sistema $Ax = b$, decompões $A$ em um  matriz triangular inferior $L$ com diagonal 1 e em uma matriz triangular inferior $U$. Fazemos essa decomposição pois temos algoritmos rápidos para resolver sistema triangulares.\n",
    "\n",
    "$A = LU$\n",
    "\n",
    "$\\left[\\begin{array}{c c c c c}\n",
    "{a_{11}}&  a_{12}&  a_{13}& \\cdots& a_{1n}\\\\ \n",
    "a_{21}&  a_{22}&  a_{23}& \\cdots& a_{2n}\\\\\n",
    "a_{31}&  a_{32}&  a_{33}& \\cdots& a_{3n}\\\\\n",
    "\\vdots& & & & \\vdots&\\\\\n",
    "a_{n1}&  a_{n2}&  a_{n3}& \\cdots& a_{nn}\\end{array}\\right] =  \\left[\\begin{array}{c c c c c}\n",
    "{1}&  &  &  & \\\\ \n",
    "l_{21}&  1& & & \\\\\n",
    "l_{31}&  l_{32}&  1& &\\\\\n",
    "\\vdots& & & \\ddots& \\\\\n",
    "l_{n1}&  l_{n2}&  l_{n3}& \\cdots& 1\\end{array}\\right] \\cdot \\left[\\begin{array}{c c c c c}{u_{11}}&  u_{12}&  u_{13}& \\cdots& u_{1n}\\\\ \n",
    "&  u_{22}&  u_{23}& \\cdots& u_{2n}\\\\\n",
    "&  &  u_{33}& \\cdots& u_{3n}\\\\\n",
    "& & & \\ddots & \\vdots&\\\\\n",
    "&  &  & & u_{nn}\\end{array}\\right]$ \n",
    "\n",
    "Para resolver\n",
    "\n",
    "$Ax = b \\Leftrightarrow LUx = b$\n",
    "\n",
    "Primeiro chamamos $Ux$ de $y$ ficando com $L\\underset{y}{\\underbrace{Ux}}= b$, então resolvemos esse o sistema triangular inferior $Ly=b$.\n",
    "\n",
    "Depois de encontrar o $y$ resolvemos o sistema triangular superior $Ux = y$ e encontramos o resultado do sistema $Ax=b$ de forma mais simples.\n",
    "\n",
    "Como calcular $L$ e $U$\n",
    "\n",
    "Para calcular os termos de $L$ e $U$ podemos usar os seguintes termos gerais:\n",
    "\n",
    "$u_{ij} = a_{ij} - \\sum _{k=1}^{i-1}l_{ik}u_{kj}$\n",
    "\n",
    "\n",
    "$l_{ij} = \\frac{a_{ij} - \\sum _{k=1}^{j-1}l_{ik}u_{kj}}{u_{jj}}$\n",
    "\n",
    "Primeiro calcula uma linha de $U$ depois uma coluna de $L$, pois eles são dependentes.\n",
    "\n",
    "Para garantir que pode existir LU\n",
    " \n",
    "### Menores Principais\n",
    "\n",
    "Se $A$ possui todos os menores principais não-singulares, isto é, $det(A_{k})\\neq 0, k=1,…,n-1$ podemos garantir que existem uma única $L$ e uma única $U$, tal que $A = LU$\n",
    "\n",
    "Se $A$ possui o último menor principal $\\neq0$, isto é, $det(A_{n})\\neq 0$ podemos garantir que o sistema linear tem apenas uma solução\n",
    "\n",
    "onde $A_{1} = a_{11}, A_{2} = \\begin{bmatrix}, ...\n",
    " a_{11}& a_{12} \\\\ \n",
    " a_{21}& a_{12} \n",
    "\\end{bmatrix}$\n",
    "\n",
    "### Propriedades\n",
    "\n",
    "Uma outra aplicação de $LU$ é para calculo de determinante.\n",
    "\n",
    "Então $A=LU \\Rightarrow det(A) = det(LU)\\Rightarrow det(A) = det(L)det(U)$, como determinante de uma matriz triangular é a multiplicação dos elementos da diagonal da matriz ficamos com $det(A) = \\underset{1}{\\underbrace{det(L)}}det(U$).\n",
    "\n",
    "Assim, para calcular o determinante de $A$ é só multiplicar os elementos da diagonal da matriz $U$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lu_decomposition(A, b):\n",
    "    U = A.copy()\n",
    "    b = b.copy()\n",
    "    \n",
    "    n = len(b)\n",
    "    L = np.eye(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        pivot = U[i, i]\n",
    "            \n",
    "        for k in range(i+1, n):\n",
    "            m = U[k, i]/pivot\n",
    "            U[k] = U[k] - U[i]*m\n",
    "            b[k] = b[k] - b[i]*m\n",
    "            \n",
    "            L[k, i] = m\n",
    "    \n",
    "    return L, U, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-1,2,-2,1], [-2,2,-3,0], [-2,0,-1,-3], [-2,0,0,-2]])\n",
    "b = np.array([1,1,1,1])\n",
    "\n",
    "L, U, b = lu_decomposition(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 1], \n",
    "              [0, 0]])\n",
    "\n",
    "b = np.array([1,1])\n",
    "\n",
    "L, U, b = lu_decomposition(A, b)\n",
    "L@U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [2, 1, 0, 0],\n",
       "       [2, 2, 1, 0],\n",
       "       [2, 2, 2, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E1 = np.array([[1,0,0,0], \n",
    "               [2,1,0,0], \n",
    "               [2,0,1,0], \n",
    "               [2,0,0,1]])\n",
    "\n",
    "E2 = np.array([[1,0,0,0], \n",
    "               [0,1,0,0], \n",
    "               [0,2,1,0], \n",
    "               [0,2,0,1]])\n",
    "\n",
    "E3 = np.array([[1,0,0,0], \n",
    "               [0,1,0,0], \n",
    "               [0,0,1,0], \n",
    "               [0,0,2,1]])\n",
    "\n",
    "E1@E2@E3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminação Gaussiana\n",
    "\n",
    "###  Relembrando conceitos\n",
    "\n",
    "#### Sistemas Lineares equivalentes\n",
    "\n",
    " - Dois sistemas são ditos equivalentes se possuem a mesma solução\n",
    " \n",
    " ##### Operações Elementares\n",
    " \n",
    "     Denotando $L_{i}$ a $i$-ésima linha de um sistema linear, temos 3 operações elementares:\n",
    "     \n",
    "     1. Trocar duas linhas no sistema: $L_{i}\\leftrightarrow L_{j}$\n",
    "     2. Multiplicar uma linha por um escalar $\\lambda \\neq 0: L_{i}\\leftarrow \\lambda L_{i}$\n",
    "     3. Somar a uma linha um múltiplo de uma outra linha: $L_{i}\\leftarrow L_{i}+\\lambda L_{j}$\n",
    "     \n",
    "     Dessas três operações apenas a $3^{o}$ preserva o determinante:\n",
    "     \n",
    "     Prova:\n",
    "     Dada as matrizes A e B\\\n",
    "     \\\n",
    "     $A = \\begin{bmatrix}... \\\\l_{j}\\\\ ...\\\\l_{i}\\\\...\\end{bmatrix} \\bar{A} =\\begin{bmatrix}... \\\\l_{j}\\\\ ...\\\\l_{j}+\\lambda l_{j}\\\\...\\end{bmatrix}$\n",
    "     \n",
    "     $det(\\bar{A}) = det\\left (\\begin{bmatrix}... \\\\l_{j}\\\\ ...\\\\l_{j}+\\lambda l_{j}\\\\...\\end{bmatrix}\\right )\n",
    " =  det\\left (\\begin{bmatrix}... \\\\l_{j}\\\\ ...\\\\l_{i}\\\\...\\end{bmatrix}\\right )+ \\lambda det\\left (\\begin{bmatrix}... \\\\l_{j}\\\\ ...\\\\l_{j}\\\\...\\end{bmatrix}\\right) = det\\left (\\begin{bmatrix}... \\\\l_{j}\\\\ ...\\\\l_{i}\\\\...\\end{bmatrix}\\right ) + \\lambda 0 = det(A) $\n",
    "     \n",
    "     \n",
    " - Se um sistema linear é obtido partir de outro sistema através de uma sequência finita de operações elementares, são equivalentes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminação Gaussiana\n",
    "\n",
    "A eliminação de gauss tem o objetivo de transformar um sistema linear complicado em um equivalente fácil de resolver por exemplo um triangular, preservando o determinante.\n",
    "\n",
    "###  Relembrando conceitos\n",
    "\n",
    "#### Sistemas Lineares equivalentes\n",
    "- Dois sistemas são ditos equivalentes se possuem a mesma solução\n",
    "- Se um sistema linear é obtido partir de outro sistema através de uma sequência finita de operações elementares, são equivalentes\n",
    "\n",
    "#### Operações Elementares\n",
    "  \n",
    "  Denotando $L_{i}$ a $i$-ésima linha de um sistema linear, temos 3 operações elementares:\n",
    "  \n",
    "  1. Trocar duas linhas no sistema: $L_{i}\\leftrightarrow L_{j}$\n",
    "  2. Multiplicar uma linha por um escalar $\\lambda \\neq 0: L_{i}\\leftarrow \\lambda L_{i}$\n",
    "  3. Somar a uma linha um múltiplo de uma outra linha: $L_{i}\\leftarrow L_{i}+\\lambda L_{j}$\n",
    "     \n",
    "  Dessas três operações apenas a $3^{o}$ preserva o determinante:\n",
    "     \n",
    "     Prova:\n",
    "     Dada as matrizes $A$ e $\\bar{A}$\\\n",
    "     \\\n",
    "     $A = \\begin{bmatrix}... \\\\l_{j}\\\\ ...\\\\l_{i}\\\\...\\end{bmatrix} \\bar{A} =\\begin{bmatrix}... \\\\l_{j}\\\\ ...\\\\l_{j}+\\lambda l_{j}\\\\...\\end{bmatrix}$\n",
    "     \n",
    "     $det(\\bar{A}) = det\\left (\\begin{bmatrix}... \\\\l_{j}\\\\ ...\\\\l_{j}+\\lambda l_{j}\\\\...\\end{bmatrix}\\right )\n",
    " =  det\\left (\\begin{bmatrix}... \\\\l_{j}\\\\ ...\\\\l_{i}\\\\...\\end{bmatrix}\\right )+ \\lambda det\\left (\\begin{bmatrix}... \\\\l_{j}\\\\ ...\\\\l_{j}\\\\...\\end{bmatrix}\\right) = det\\left (\\begin{bmatrix}... \\\\l_{j}\\\\ ...\\\\l_{i}\\\\...\\end{bmatrix}\\right ) + \\lambda 0 = det(A) $\n",
    " \n",
    "\n",
    "\n",
    "###  Método\n",
    "\n",
    "Para resolver o sistema de $Ax = b$, usamos a matriz aumentada $[A|b]$ e aplicamos os seguintes passos:\n",
    "\n",
    "Dada a matriz aumentada $[A|b] =\\left[\\begin{array}{c c c c c|c}\\color{red}{a_{11}}&  a_{12}&  a_{13}& ...& a_{1n}& b_{1}\\\\ a_{21}&  a_{22}&  a_{23}& ...& a_{2n}& b_{2}\\\\ a_{31}&  a_{32}&  a_{33}& ...& a_{3n}& b_{3}\\\\ \\vdots& & & & \\vdots& \\vdots\\\\ a_{n1}&  a_{n2}&  a_{n3}& ...& a_{nn}& b_{n}\\end{array}\\right]$\n",
    "\n",
    "1) Escolhe um pivô arbitrário, nesse caso $a_{11}$\\\n",
    "2) Zerar todos os valores abaixo do pivô\n",
    "\n",
    "Para isso vamos usar a $3^{o}$ operação $L_{2}\\leftarrow L_{2}+ m_{21} L_{1}$, para zerar o primeiro elemento de $L_{2}$, que é nosso objetivo, o $m_{21}$ será igual a $m_{21} = -a_{21}/a_{11}$\n",
    "Lembrando que tem que alterar todos os valores da linha que está sendo modificada incluindo os elementos de b\n",
    "\n",
    "Ao fazer esse mesmo procedimento para todas as outras linhas $L_{i}\\leftarrow L_{i}+ m_{i1} L_{1}$, onde $i=(2,3,...,n)$ com $m_{i1} = -a_{i1}/a_{11}$, zeramos todos os elementos abaixo do pivô.\n",
    "\n",
    "3) Escolhe um novo pivô e faz o mesmo procedimento agora visando zerar os elementos da  $2^{a}$ coluna\n",
    "\n",
    "$[A|b] = \\left[\\begin{array}{c c c c c|c}{a_{11}}& a_{12}&  a_{13}& ...& a_{1n}& b_{1}\\\\ 0&  \\color{red}{a_{22}}&  a_{23}& ...& a_{2n}& b_{2}\\\\ 0&  a_{32}&  a_{33}& ...& a_{3n}& b_{3}\\\\ \\vdots& & & & \\vdots& \\vdots\\\\ 0&  a_{n2}&  a_{n3}& ...& a_{nn}& b_{n}\\end{array}\\right]$\n",
    "\n",
    "\n",
    "Fazendo $L_{i}\\leftarrow L_{i}+ m_{i2} L_{2}$, onde $i=(3,4,...,n)$ com $m_{i2} = -a_{i2}/a_{22}$, zeramos os elementos da $2^{a}$ coluna\n",
    "\n",
    "4) Vamos fazer esse procedimento até $L_{i}\\leftarrow L_{i}+ m_{i,n-1} L_{n-1}$, onde $i=(3,4,...,n)$ com $m_{i,n-1} = -a_{i,n-1}/a_{n-1,n-1}$\n",
    "\n",
    "$[A|b] =\\left[\\begin{array}{c c c c c|c}{a_{11}}& a_{12}&  a_{13}& ...& a_{1n}& b_{1}\\\\ 0& {a_{22}}&  a_{23}& ...& a_{2n}& b_{2}\\\\ 0&  0&  a_{33}& ...& a_{3n}& b_{3}\\\\ \\vdots& & & & \\vdots& \\vdots\\\\ 0&  0&  0& ...& a_{nn}& b_{n}\\end{array}\\right]$\n",
    "\n",
    "\n",
    "5) O resultado final é um sistema triangular e é só fazer as substituições e encontrar os resultados desse sistema\n",
    "\n",
    "### Eliminação de Gauss e LU\n",
    "\n",
    "#### Foma Matricial\n",
    "\n",
    "Podemos representar as operações de forma matricial, temos uma equação $Ax = b$\n",
    "\n",
    "1) Anular todos os elementos abaixo do pivô, multiplicando os dois lados da expressão por nossa $M_{1}$, tendo agora uma $A_{1}$ que tem todos os elementos abaixo do pivo = 0 \n",
    "\n",
    "$M_{1} A x = M_{1} b \\Leftrightarrow \\left[\\begin{array}{c c c c c}1&  &  & & \\\\ m_{21}&  1&  & & \\\\ m_{31}&  &  1& &\\\\ \\vdots& & & \\ddots& \\\\ m_{n1}&  &  & & 1\\end{array}\\right]\\cdot\\left[\\begin{array}{c c c c c}\\color{red}{a_{11}}&  a_{12}&  a_{13}& ...& a_{1n}\\\\ a_{21}&  a_{22}&  a_{23}& ...& a_{2n}\\\\ a_{31}&  a_{32}&  a_{33}& ...& a_{3n}\\\\ \\vdots& & & & \\vdots\\\\ a_{n1}&  a_{n2}&  a_{n3}& ...& a_{nn}\\end{array}\\right]\\cdot x = M_{1}b\\Leftrightarrow \\left[\\begin{array}{c c c c c}{a_{11}}& a_{12}&  a_{13}& ...& a_{1n}\\\\ 0&  \\color{red}{a_{22}}&  a_{23}& ...& a_{2n}\\\\ 0&  a_{32}&  a_{33}& ...& a_{3n}\\\\ \\vdots& & & & \\vdots\\\\ 0&  a_{n2}&  a_{n3}& ...& a_{nn}\\end{array}\\right]\\cdot x = M_{1}b$ \n",
    "\n",
    "2) Anular todos os elementos abaixo do pivô, agora temos a expressão $A_{1}x = M_{1}b$, ao multiplicar $A_{1}$ po toda da expressão geramos uma $A_{2}$ com os elementos zerados \n",
    "\n",
    "$M_{2}A_{1}x = M_{2}M_{1} b \\Leftrightarrow \\left[\\begin{array}{c c c c c}1&  &  & & \\\\ &  1&  & & \\\\ &  m_{32}&  1& &\\\\ & \\vdots& & \\ddots& \\\\ &  m_{n2}&  & & 1\\end{array}\\right]\\cdot\\left[\\begin{array}{c c c c c}{a_{11}}& a_{12}&  a_{13}& ...& a_{1n}\\\\ 0&  \\color{red}{a_{22}}&  a_{23}& ...& a_{2n}\\\\ 0&  a_{32}&  a_{33}& ...& a_{3n}\\\\ \\vdots& & & & \\vdots\\\\ 0&  a_{n2}&  a_{n3}& ...& a_{nn}\\end{array}\\right]\\cdot x = M_{2}M_{1}b\\Leftrightarrow \\left[\\begin{array}{c c c c c}{a_{11}}& a_{12}&  a_{13}& ...& a_{1n}\\\\ 0& {a_{22}}&  a_{23}& ...& a_{2n}\\\\ 0&  0&  a_{33}& ...& a_{3n}\\\\ \\vdots& & & & \\vdots& \\vdots\\\\ 0&  0&  a_{n3}& ...& a_{nn}\\end{array}\\right]\\cdot x = M_{2}M_{1}b$\n",
    "\n",
    "3) Faz o mesmo procedimento para todas colunas até chegar no pivo $a_{n-1,n-1}$ gerando nossa matriz com a triangular inferior que utilizamos para resolver o sistema de forma simples\n",
    "\n",
    "$M_{n-1}A_{n-1}x = M_{n-1}...M_{1} b \\Leftrightarrow \\left[\\begin{array}{c c c c c}1&  &  & & \\\\ &  1&  & & \\\\ &  &  1& &\\\\ & & & \\ddots& \\\\ &  &  & m_{n,n-1}& 1\\end{array}\\right]\\cdot\\left[\\begin{array}{c c c c c}{a_{11}}&  a_{12}&  a_{13}& ...& a_{1,n-1}& a_{1n}\\\\ 0&  a_{22}&  a_{23}& ...& a_{2,n-1}& a_{2n}\\\\ 0&  0&  a_{33}& ...& a_{3,n-1}& a_{3n}\\\\ \\vdots& & & & \\vdots\\\\ 0&  0&  0& ...& a_{n,n-1}& a_{nn}\\end{array}\\right]\\cdot x = M_{n-1}...M_{1}b\\Leftrightarrow \\left[\\begin{array}{c c c c c}{a_{11}}&  a_{12}&  a_{13}& ...& a_{1,n-1}& a_{1n}\\\\ 0&  a_{22}&  a_{23}& ...& a_{2,n-1}& a_{2n}\\\\ 0&  0&  a_{33}& ...& a_{3,n-1}& a_{3n}\\\\ \\vdots& & & & \\vdots\\\\ 0&  0&  0& ...& 0& a_{nn}\\end{array}\\right]\\cdot x = M_{n-1}...M_{1}b$\n",
    "\n",
    "Dessa forma conseguimos fazer a fatoração $LU$ justamente utilizando a eliminação de gauss, nossa $U$ neste caso é justamente a nossa matriz triangular final \n",
    "\n",
    "$U = \\left[\\begin{array}{c c c c c}{a_{11}}&  a_{12}&  a_{13}& ...& a_{1,n-1}& a_{1n}\\\\ 0&  a_{22}&  a_{23}& ...& a_{2,n-1}& a_{2n}\\\\ 0&  0&  a_{33}& ...& a_{3,n-1}& a_{3n}\\\\ \\vdots& & & & \\vdots\\\\ 0&  0&  0& ...& 0& a_{nn}\\end{array}\\right]$\n",
    "\n",
    "Para achar a $L$ é um pouco mais indireto mas sabemos que $A_{n-1}x = M_{n-1}...M_{1}b$ e que $A_{n-1} = U$, então podemos afirmar que $Ux = M_{n-1}...M_{1}b$ como $LUx = b$ podemos dizer que $L = (M_{n-1}...M_{1})^{-1} \\Leftrightarrow L = M^{-1} = M^{-1}_{1}M^{-1}_{2}...M^{-1}_{n-1}$ ou seja :\n",
    "\n",
    "$L = \\left[\\begin{array}{c c c c c}1&  &  & & \\\\ -m_{21}&  1&  & & \\\\ -m_{31}& -m_{32}&  1& &\\\\ \\vdots& \\vdots& \\vdots& \\ddots& \\\\ -m_{n,1}& -m_{n,2} & -m_{n,3} & -m_{n,n-1}& 1\\end{array}\\right]$\n",
    "\n",
    "### Pivô igual ou próximo de 0\n",
    "\n",
    "Quando o pivô é 0 não podemos utilizar o método de gauss para calcular os $m_{ij}$ nós dividimos pelo pivô e não pode fazer divisão por 0, por isso são necessárias adaptações.\n",
    "\n",
    "No caso de ser próximo ao 0 também ocorrem problemas de aproximação e o resultado pode ficar errado.\n",
    "\n",
    "Por isso o método precisa ser mudado e fazemos um procedimento chamado pivoteamento parcial.\n",
    "\n",
    "#### Pivoteamento parcial\n",
    "\n",
    "Pivoteamento de linha, o pivoteamento total leva em conta linha e coluna mas é muito custoso computacionalmente\n",
    "\n",
    "Para cada passo $k$ ao invés de escolher um pivô arbitrário, escolhe para ser o pivô o maior elemento da coluna em módulo. Ao encontrar permuta a linha que contêm esse maior elemento com a linha $k$, depois só fazer o método de eliminação de gauss demonstrado anteriormente.\n",
    "\n",
    "Para permutar as linhas pela forma matricial é so fazer $P\\cdot A$. O $P$ será justamente a matriz identidade com as linhas referentes permutadas. Por exemplo, se quero permutar na minha matriz $A$ a linha $i$ com a linha $j$ só pegar a matriz identidade permutar a linha $i$ com a linha $j$ e multiplicar pela $A$.\n",
    "\n",
    "#### Decomposição LU\n",
    "\n",
    "Caso um dos menores pricipais seja singular não pode fazer a decomposição $LU$ da forma normal, então fazemos da seguinte forma: \n",
    "\n",
    "$$P \\cdot A = L \\cdot U$$ onde P é a matriz de permutações.\n",
    "\n",
    "Para resolver:\n",
    "Sabemos que $Ax = B \\Leftrightarrow (LU)x = (PA)x = Pb$\n",
    "\n",
    "1) Resolver $Ly = PB$ encontrando o valor de $y$\\\n",
    "2) Resolver $Ux = y$ \n",
    "\n",
    "Para achar $U$ pode ser feita da mesma forma sem o pivoteamento então $U$ é justamente a matriz triangular resultante da eliminação de gauss\n",
    "\n",
    "Para $L$ é um pouco diferente, vale lembrar que a $U$ sem o pivoteamento parcial $U = M_{n-1}...M_{2}M_{1}A$, já com o pivoteamento multiplicamos cada etapa pela permutação necessária então fica  $U = M_{n-1}P_{n-1}...M_{2}P_{2}M_{1}P_{1}A$.\n",
    "\n",
    "Isolando $A$ podemos deixar a expressão da forma $A = (M_{n-1}P_{n-1}...M_{2}P_{2}M_{1}P_{1})^{-1}U$, ao multiplicar $P$, sendo $P$ a composição de todas as permutações que foram feitas, dos dois lados chegamos na forma $AP = P(M_{n-1}P_{n-1}...M_{2}P_{2}M_{1}P_{1})^{-1}U$. Já que $PA = LU$, podemos afirmar que $L = P(M_{n-1}P_{n-1}...M_{2}P_{2}M_{1}P_{1})^{-1}$.\n",
    "\n",
    "\n",
    "### Se sobrar falo de calculo da inversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_elimination(A, b):\n",
    "    A = A.copy()\n",
    "    b = b.copy()\n",
    "    \n",
    "    n = len(b)\n",
    "    \n",
    "    for i in range(n):\n",
    "        pivot = A[i, i]\n",
    "            \n",
    "        for k in range(i+1, n):\n",
    "            m = A[k, i]/pivot\n",
    "            A[k] = A[k] - A[i]*m\n",
    "            b[k] = b[k] - b[i]*m\n",
    "    \n",
    "    return A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_upper(A, b):\n",
    "    A = A.copy()\n",
    "    b = b.copy()\n",
    "    \n",
    "    n = len(b)\n",
    "    solution = []\n",
    "    \n",
    "    for i in range(n-1, -1, -1):\n",
    "        sum_ = np.sum(A[i, i+1:n])\n",
    "        current_solution = (b[i] - sum_)/A[i,i]\n",
    "    \n",
    "        solution.append(current_solution)\n",
    "        A[:, i] = A[:, i] * current_solution\n",
    "        \n",
    "    return solution[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_lower(A, b):\n",
    "    A = A.copy()\n",
    "    b = b.copy()\n",
    "    \n",
    "    n = len(b)\n",
    "    solution = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        sum_ = np.sum(A[i, 0:i])\n",
    "        current_solution = (b[i] - sum_)/A[i,i]\n",
    "    \n",
    "        solution.append(current_solution)\n",
    "        A[:, i] = A[:, i] * current_solution\n",
    "        \n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cholesky(A):\n",
    "    n = len(A)\n",
    "    L = np.zeros((n, n))\n",
    "    \n",
    "    L[0, 0] = np.sqrt(A[0, 0])\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        for j in range(0, i+1):\n",
    "            sum_ = 0\n",
    "            for k in range(0, j):\n",
    "                sum_ += L[i, k] * L[j, k]\n",
    "            \n",
    "            if i == j:           \n",
    "                L[i, i] = np.sqrt(A[i, i] - sum_)\n",
    "            else:\n",
    "                L[i, j] = (A[i, j] - sum_)/L[j, j]\n",
    "    \n",
    "    return L, L.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposição de Cholesky\n",
    "\n",
    "### SPD\n",
    "\n",
    "Uma matriz simétrica $A \\in \\mathcal{M}_{n,n} (A = A^{t})$ é dita simétrica positiva\n",
    "definida (SPD), se $x^{t} \\cdot Ax > 0$, para todo vetor não-nulo $v\\in \\mathbb{R}^{n}$.\n",
    "\n",
    "Para testar se a matriz simétrica $A$ é SPD podemos checar os testes abaixo, se um deles estiver sendo garantido então podemos afirmar que é SPD:\n",
    "\n",
    "1) $det(A_{k})>0,k=1,2,...,n$; \\\n",
    "2) todos os autovalores de $A$ são positivos \n",
    "\n",
    "Para provar isso podemos pegar por exemplo uma matriz diagonal e fazer a operação $x^{t} \\cdot Dx > 0$, o resultado será $a_{11}x_{1}^{2} + a_{22}x_{2}^{2} + a_{33}x_{3}^{2}+...+a_{nn}x_{n}^{2}$\n",
    "\n",
    "Então se eu tenho um $a_{i}<0$ e o vetor $x$ todos os elementos são 0, exceto a o $x_{i}$ que é 1, ao fazer o $\\sum_{i=1}^{n}{a_{i}x_{i}^{2}} =  a_{i} < 0$. E para ser SVD sabemos que $x^{t} \\cdot Ax > 0$, então para que isso aconteça todos os $a_{i}$ precisam ser maiores que 0. \n",
    "\n",
    "Então se $A$ é diagonal e SPD $\\Rightarrow a_{i}>0$\n",
    "\n",
    "Agora pensando em uma matriz genérica $A$, primeiro diagonalizamos ela ficando com $P^{-1}DP$, escolhendo uma $P$ ortogonal podemos escrever como $P^{t}DP$, substituindo na equação $x^{t}Ax$ ficamos com  $x^{t}Ax = \\underset{(Px)^{t}}{\\underbrace{x^{t}P^{t}}}DPx$, chamando $Px$ de $y$ ficamos com $y^{t}Dy$.\n",
    "\n",
    "Então podemos afirmar que $x^{t}Ax >0 \\Leftrightarrow y^{t}Dy >0$, e sabemos que para a expressão $y^{t}Dy >0$ somente se os $d_{i}>0$. Como diagonalizamos a $A$ sabemos que os $d_{i}$ são os autovalores de $A$, então para que a matriz $A$ seja $SPD$ é necessário que todos os autovalores da mesma sejam positivos, como queríamos demonstrar.\n",
    "\n",
    "Como o determinante é o produto dos autovalores e os autovalores precisam ser maiores que 0 para ser SPD, então o determinante também precisa ser maior que 0 para ser SPD.\n",
    "\n",
    "### Método\n",
    "\n",
    "Sendo SPD podemos utilizar a decomposição de Cholesky, mais eficiente que a decomposição $LU$. Vamos decompor a matriz $A$ em $A = H \\cdot H^{T}$, sendo $H$ uma matriz triangular inferior com os elementos da diagonal $>0$\n",
    "\n",
    "$H = \\left[\\begin{array}{c c c c c}\n",
    "{h_{11}}& &  & & \\\\ \n",
    "h_{21}&  h_{22}& & & \\\\\n",
    "h_{31}&  h_{32}&  h_{33}& & \\\\\n",
    "\\vdots& \\vdots& \\vdots& \\ddots& &\\\\\n",
    "h_{n1}&  h_{n2}&  h_{n3}& \\cdots& h_{nn}\\end{array}\\right]$\n",
    "\n",
    "Para encontrar os elementos de $H$ podemos usar o termo geral:\n",
    "\n",
    "1) Para diagonal \n",
    "\n",
    "$\\left\\{\\begin{matrix}\n",
    "h_{11} = \\sqrt{a_{11}},\\\\\n",
    "h_{ii} = (a_{ii} - \\sum_{k=1}^{j-1}{h_{ik}^{2}})^{1/2} \n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "2) Fora da diagonal\n",
    "\n",
    "$\\left\\{\\begin{matrix}h_{i1} = \\frac{a_{i1}}{h_{11}}, i = 2,3,...,n , \\\\\n",
    "h_{ij} = \\frac{(a_{ij}- \\sum_{k=1}^{j-1}{h_{ik}h_{jk}})}{h_{jj}}, 2 \\leq j < i \\end{matrix}\\right.$\n",
    "\n",
    "## COMPARAR EFICIENCIA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cholesky.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_cholesky(A, b):\n",
    "    # https://homepages.dcc.ufmg.br/~ana.coutosilva/Aulas-CN/SistemasLineares/Cholesky.pdf\n",
    "    \n",
    "    L, Lt = cholesky(A)\n",
    "    y = solve_lower(L, b)\n",
    "    \n",
    "    solution = solve_upper(Lt, y)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauss-Jacobi\n",
    "\n",
    "\n",
    "![jacobi](images/jacobi.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi(A, b):\n",
    "    n = len(b)\n",
    "    x = np.random.rand(n)\n",
    "    k = np.random.rand(n)\n",
    "    \n",
    "    for _ in range(1000):\n",
    "        for i in range(n):\n",
    "            sum_ = 0\n",
    "            for j in range(n):   \n",
    "                if i != j:\n",
    "                    sum_ += A[i, j] * k[j]\n",
    "            \n",
    "            x[i] = (b[i] - sum_)/A[i, i]\n",
    "        \n",
    "        if np.linalg.norm(x-k)/np.linalg.norm(x) < 1e-9:\n",
    "            break\n",
    "        else:\n",
    "            k = x.copy()\n",
    "            \n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos iterativos\n",
    "<!-- ![seidel](images/seidel.jpg) -->\n",
    "\n",
    "Se tiver limitaçao computacional para usar um método numérico, não tem memória suficiente por exemplo, devemos usar os metodos iterativos.\n",
    "\n",
    "## Conceitos\n",
    "\n",
    "Dados um sistema $Ax = b$, a ideia do método iterativo é partir de um chute inicial $x^{(0)}$ em $\\mathbb{R}^{n}$ chegar iterativamente em um $x^{(k)}$, onde $k$ simboliza o número da iteração, que convirga para o correto. Formalmente:\n",
    "\n",
    "Uma sequência de vetores { $x^{(0)},x^{(1)},...,x^{(k)}$ } converge para um vetor $x$, se: \n",
    "\n",
    "$\\lim_{x \\to\\infty}\\left \\| x^{(k)}- x \\right \\|= 0$\n",
    "\n",
    "\n",
    "Para todos os métodos o ideia é semelhante:\n",
    "\n",
    "1) É preciso transformar o sistema $Ax = b$ em um sistema equivalente\n",
    "\n",
    "$$x = Cx + g,$$ em que $C \\in \\mathcal{M}(n,n)$ e $g\\in\\mathbb{R}^{n}$ são conhecidos.\n",
    "\n",
    "Para isso, por exemplo podemos dizer que $C = I - A$ e $g = b$, substituindo na equação $x = Cx + g$ temos $x = (I-A)x + b \\Leftrightarrow x = Ix - Ax +b \\Leftrightarrow x = x - Ax +b  \\Leftrightarrow Ax = b$ \n",
    "\n",
    "\n",
    "2) Dado um $x^{(0)}$, obtemos a sequência {$x^{(0)}, x^{(1)},...$} através do método iterativo, ou seja, a partir de um chute inicial $x^{(0)}$ consiguiremos todos os outros:\n",
    "\n",
    "$$x^{(k+1)} = C x^{(k)} + g, k=0,1,2,...$$\n",
    "\n",
    "### Convergência \n",
    "\n",
    "#### Critério geral de convergência \n",
    "\n",
    "Seja { $x^{(0)},x^{(1)},...,x^{(k)}$ } sequência gerada pelo processo iterativo $x^{(k+1)} = C x^{(k)} + g$, k=0,1,2,...:\n",
    "\n",
    "1) Se $\\left \\| C \\right \\|_{M}< 1,$ onde $\\left \\| \\cdot \\right \\|_{M}$ é uma norma consistente, então a sequência converge.\n",
    "\n",
    "2) $x^{(k)} \\rightarrow x$ se somente se o raio espectral de $C$ < 1 .\n",
    "\n",
    "#### Prova\n",
    "\n",
    "Como provar que $\\left \\| x^{(k)}- x \\right \\|_{v}\\rightarrow 0$ ou simplesmente $x^{(k)} \\rightarrow x$, provar atravez do critério de convergência 1:\n",
    "\n",
    "Sabemos que $Ax = b \\Leftrightarrow x = Cx +b$ e que o processo iterativo se da da seguinte forma $x^{(k+1)} = C x^{(k)} + g$\n",
    "\n",
    "Diminuindo $x$ dos dois lados $x^{(k+1)} - x = C x^{(k)} + g - x$, sabendo que $x = Cx + g$ podemos substituir no segundo lado da expressão tendo agora $x^{(k+1)} - x = C x^{(k)} + g - Cx - g \\Leftrightarrow x^{(k+1)} - x = C ( x^{(k)} - x)$\n",
    "\n",
    "Aplicando módulo dos dois lados, fica $\\left \\| x^{(k+1)} - x \\right \\| = \\left \\| C ( x^{(k)} - x) \\right \\|$ e usando a hipótese podemos dizer que existe uma norma consistente de matriz então podemos separar ficando com $\\left \\| x^{(k+1)} - x \\right \\| \\leq \\left \\| C \\right \\|\\left \\|( x^{(k)} - x) \\right \\|$\n",
    "\n",
    "Sabemos então que $\\left \\| x^{(k+1)} - x \\right \\| \\leq \\left \\| C \\right \\|\\left \\|( x^{(k)} - x) \\right \\|$, a partir disso podemos inferir que $\\left \\|( x^{(k)} - x) \\right \\| \\leq \\left \\| C \\right \\|\\left \\|( x^{(k-1)} - x) \\right \\| $, ao substituir esse valor encontrado ficamos com a expressão $\\left \\| x^{(k+1)} - x \\right \\| \\leq \\left \\| C \\right \\|\\left \\| C \\right \\|\\left \\|( x^{(k-1)} - x) \\right \\|$\n",
    "\n",
    "Podemos repetir esse processo até chegarmos na equação $\\left \\| x^{(k+1)} - x \\right \\| \\leq \\left \\| C \\right\\|^{k} \\left \\|( x^{(0)} - x) \\right \\|$\n",
    "\n",
    "Ao aplicar limite $\\lim_{k \\to\\infty}\\left \\| C \\right\\|^{k} \\underset{cte}{\\underbrace{\\left \\|( x^{(0)} - x) \\right \\|}}$, se tem um número elevado a $k$, onde $k \\rightarrow \\infty$ para esse número ir para a 0 apenas se $C<1$ que nesse caso por hipótese é verdade. Então chegamos que o resultado de $\\lim_{k \\to\\infty}\\left \\| C \\right\\|^{k} \\left \\|( x^{(0)} - x) \\right \\| = 0$\n",
    "\n",
    "Como $0\\leq\\left \\| x^{(k+1)} - x \\right \\| \\leq \\left \\| C \\right\\|^{k} \\left \\|( x^{(0)} - x) \\right \\|$, ao aplicar limite em toda a expressão sabemos que o limite com $k \\rightarrow 0$ é 0 e o limite da parte direita também foi provado que é 0, então pelo teorema de confronto podemos afirmar que $\\lim_{k \\to\\infty}\\left \\| x^{(k+1)} - x \\right \\|=0$, como queríamos demonstrar.\n",
    "\n",
    "### Critério de parada\n",
    "\n",
    "1) Erro absoluto, ao satisfazer a condição abaixo o processo é finalizado:\n",
    "\n",
    "$$\\left \\| x^{(k+1)} - x^{(k)}\\right \\| < \\varepsilon $$\n",
    "\n",
    "2) Erro relativo, usado quando não quer levar em conta a ordem de grandeza, ao satisfazer a condição abaixo o processo é finalizado:\n",
    "\n",
    "$$\\frac{\\left \\| x^{(k+1)} - x^{(k)}\\right \\|}{x^{(k+1)}}<\\varepsilon $$\n",
    "\n",
    "3) Teste de resíduo, dessa forma vemos se o $Ax^{(k)}$ está tendendo ao $b$, ou seja o $x^{(k)$ próximo do $x$ correto, ao satisfazer a condição abaixo o processo é finalizado:\n",
    "\n",
    "$$\\left \\| b - Ax^{(k)}\\right \\| < \\varepsilon $$\n",
    "\n",
    "4) Número de iterações, ao satisfazer a condição abaixo o processo é finalizado:\n",
    "\n",
    "$$k = k_{max} $$\n",
    "\n",
    "\n",
    "Norma é considerada consistente se:\n",
    "$\\left \\| Ax \\right \\|_{v}\\leq \\left \\| A \\right \\|_{M}\\left \\| x \\right \\|_{v}$\n",
    "\n",
    "\n",
    "## Método de Gauss-Jacobi\n",
    "\n",
    "Para selecionar o $C$ e a $g$ no método de gauss-jacobi:\n",
    "\n",
    "Dado $Ax=b$\n",
    "\n",
    "$\\left\\{\\begin{matrix}\n",
    " a_{11}{\\color{Red} {x_{1}}} + a_{12}x_{2} +a_{13}x_{3}+ ...+ a_{1n}x_{n}  = b_{1} \\\\ \n",
    " a_{21}x_{1} + a_{22}{\\color{Red} x_{2}} +a_{23}x_{3}+ ...+ a_{2n}x_{n}  = b_{2} \\\\ \n",
    " a_{31}x_{1} + a_{32}x_{2} +a_{33}{\\color{Red} x_{3}}+ ...+ a_{3n}x_{n}  = b_{3} \\\\ \n",
    " \\vdots \\\\\n",
    " a_{n1}x_{1} + a_{n2}x_{2} +a_{n3}x_{3}+ ...+ a_{nn}{\\color{Red} x_{n}}  = b_{n} \\\\ \n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "1) Isola cada coordenada$x_{i}$ da diagonal da matriz $A$\n",
    "\n",
    "$\\left\\{\\begin{matrix}\n",
    " {\\color{Red} {x_{1}}} = (b_{1} - a_{12}x_{2} - a_{13}x_{3} - ... - a_{1n}x_{n}) / a_{11}\\\\ \n",
    " {\\color{Red} {x_{2}}} = (b_{2} - a_{21}x_{1} - a_{23}x_{3} - ... - a_{2n}x_{n}) /  a_{22} \\\\ \n",
    " {\\color{Red} {x_{3}}} = (b_{3} - a_{31}x_{1} - a_{32}x_{2} - ... - a_{3n}x_{n}) / a_{33} \\\\ \n",
    " \\vdots \\\\\n",
    " {\\color{Red} {x_{n}}} = (b_{n} - a_{n1}x_{1} - a_{n2}x_{2} - ... - a_{n,n-1}x_{n-1})) / a_{nn}\\\\ \n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "2) Transforma na forma matricial para encontrar o $g$ que seriam as partes que não multiplica $x$\n",
    "\n",
    "$g = \\begin{bmatrix}\n",
    "b_{1}/a_{11}\\\\ \n",
    "b_{2}/a_{22}\\\\ \n",
    "b_{3}/a_{33}\\\\ \n",
    "\\vdots \\\\ \n",
    "b_{n}/a_{nn}\\end{bmatrix}$\n",
    "\n",
    "3) Já para a $C$ olhamos justamente os elementos que multiplicam $x$, cada elemento da matriz é coeficiente dos $x_{i}$\n",
    "\n",
    "$C = \\begin{bmatrix}\n",
    "        0& - a_{12}/ a_{11}& - a_{13}/ a_{11}& ...& - a_{1n}/ a_{11}\\\\ \n",
    " - a_{21}/  a_{22}&        0& - a_{23}/  a_{22}& ...& - a_{2n}/  a_{22}\\\\ \n",
    " - a_{31}/ a_{33}& - a_{32}/ a_{33}&        0& ...& - a_{3n}/ a_{33}\\\\ \n",
    "  \\vdots &   \\vdots&   \\vdots&  \\ddots & \\vdots\\\\ \n",
    " - a_{n1}/ a_{nn}& - a_{n2}/ a_{nn}& ...& - a_{n,n-1}& 0\n",
    "\\end{bmatrix}$\n",
    "\n",
    "4) Depois de obter $C$ e $g$ só substituir e começar o processo iterativo $x^{(k+1)} = C x^{(k)} + g, k=0,1,2,...$\n",
    "\n",
    "$\\left\\{\\begin{matrix}\n",
    " {{x_{1}^{{\\color{Red} {(k+1)}}}}} = (b_{1} - a_{12}x_{2}^{\\color{Blue} {(k)}} - a_{13}x_{3}^{\\color{Blue} {(k)}} - ... - a_{1n}x_{n}^{\\color{Blue} {(k)}}) / a_{11}\\\\ \n",
    " {{x_{2}^{{\\color{Red} {(k+1)}}}}} = (b_{2} - a_{21}x_{1}^{\\color{Blue} {(k)}} - a_{23}x_{3}^{\\color{Blue} {(k)}} - ... - a_{2n}x_{n}^{\\color{Blue} {(k)}}) /  a_{22} \\\\ \n",
    " {{x_{3}^{{\\color{Red} {(k+1)}}}}} = (b_{3} - a_{31}x_{1}^{\\color{Blue} {(k)}} - a_{32}x_{2}^{\\color{Blue} {(k)}} - ... - a_{3n}x_{n}^{\\color{Blue} {(k)}}) / a_{33} \\\\ \n",
    " \\vdots \\\\\n",
    " {{x_{n}^{{\\color{Red} {(k+1)}}}}} = (b_{n} - a_{n1}x_{1}^{\\color{Blue} {(k)}} - a_{n2}x_{2}^{\\color{Blue} {(k)}} - ... - a_{n,n-1}x_{n-1}^{\\color{Blue} {(k)}})) / a_{nn}\\\\ \n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "### Forma Matricial\n",
    "\n",
    "Para obter $x^{(k+1)} = C x^{(k)} + g, k=0,1,2,...$ a partir de $Ax=b$ de forma matricial :\n",
    "\n",
    "Decompondo em $A = D + R$, onde D é a diagonal de $A$ e $R = A - D$  e substituindo na equação\n",
    "\n",
    "$Ax=b \\Leftrightarrow (R+D)x=b \\Leftrightarrow (R)x + Dx = b$\n",
    "\n",
    "Quem está com os elementos da diagonal está um passo a frente no método iterativo, então podemos dizer que \n",
    "\n",
    "$Rx^{(k)} + Dx^{(k+1)} = b$\n",
    "\n",
    "Isolando $x^{(k+1)} = D^{-1}((-Rx^{(k)}) + b) \\Leftrightarrow  x^{(k+1)} = \\underset{C}{\\underbrace{(-RD^{-1})}}x^{(k)} + \\underset{g}{\\underbrace{bD^{(-1)}}}$\n",
    "\n",
    "### Critérios de convergência\n",
    "\n",
    "O método de gauss-jacobi converge para a solução $Ax=b$ para qualquer $x^{(0}$ se satisfazer uma das condições abaixo:\n",
    "\n",
    "1) Critério das linhas\n",
    "Para cada linha da matriz A, tira o elemento da diagonal, soma os demais em módulo e divide pelo módulo da diagonal, se para todas as linhas for menor que 1, o método de gauss-jacobi converge, ou seja:\n",
    "\n",
    "$\\alpha = \\underset{1 \\leq k \\leq n}{max (\\alpha_{k})<1}$, com $\\alpha_{k}=\\frac{\\sum _{\\underset{j\\neq k}{j=1}}^{n}\\left | a_{kj} \\right |}{\\left | a_{kk} \\right |}$\n",
    "\n",
    "1) Critério das colunas\n",
    "A mesma coisa do método anterior agora para as colunas\n",
    "\n",
    "$\\alpha = \\underset{1 \\leq k \\leq n}{max (\\alpha_{k})<1}$, com $\\alpha_{k}=\\frac{\\sum _{\\underset{i\\neq k}{i=1}}^{n}\\left | a_{ik} \\right |}{\\left | a_{kk} \\right |}$\n",
    "\n",
    "\n",
    "## Método de Gauss-Seidel\n",
    "\n",
    "Método muito semelhante ao gauss-jacobi mas um pouco modificado de forma que a convergência acontece mais rápido. A diferença é que assim que é calculado o próximo $x$ ele já é utilizado na próxima iteração.\n",
    "\n",
    "$\\left\\{\\begin{matrix}\n",
    " {{x_{1}^{{\\color{Red} {(k+1)}}}}} = (b_{1} - a_{12}x_{2}^{\\color{Blue} {(k)}} - a_{13}x_{3}^{\\color{Blue} {(k)}} - ... - a_{1n}x_{n}^{\\color{Blue} {(k)}}) / a_{11}\\\\ \n",
    " {{x_{2}^{{\\color{Red} {(k+1)}}}}} = (b_{2} - a_{21}x_{1}^{\\color{Red} {(k+1)}} - a_{23}x_{3}^{\\color{Blue} {(k)}} - ... - a_{2n}x_{n}^{\\color{Blue} {(k)}}) /  a_{22} \\\\ \n",
    " {{x_{3}^{{\\color{Red} {(k+1)}}}}} = (b_{3} - a_{31}x_{1}^{\\color{Red} {(k+1)}} - a_{32}x_{2}^{\\color{Red} {(k+1)}} - ... - a_{3n}x_{n}^{\\color{Blue} {(k)}}) / a_{33} \\\\ \n",
    " \\vdots \\\\\n",
    " {{x_{n}^{{\\color{Red} {(k+1)}}}}} = (b_{n} - a_{n1}x_{1}^{\\color{Red} {(k+1)}} - a_{n2}x_{2}^{\\color{Red} {(k+1)}} - ... - a_{n,n-1}x_{n-1}^{\\color{Red} {(k+1)}})) / a_{nn}\\\\ \n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "### Forma matricial\n",
    "\n",
    "Os valores de $x$ que estão no passo $k+1$ são aqueles que estão sendo multiplicados pela estrutura triangular inferior da matriz $A$, incluindo a diagonal dela. Já os elementos de $x$ que estão no passo $k$ vão estar multiplicados pelos coeficientes da matriz $A$ que estão na estrutura triangular dela sem a diagonal.\n",
    "\n",
    "Para obter $x^{(k+1)} = C x^{(k)} + g, k=0,1,2,...$ a partir de $Ax=b$ de forma matricial:\n",
    "\n",
    "Decompondo em $A = L + R$, onde $L$ é matriz triangular inferior a e $R$ a matriz triangular superior sem a diagonal e substituindo na equação.\n",
    "\n",
    "$Ax=b \\Leftrightarrow (R+L)x=b \\Leftrightarrow Rx + Lx = b$\n",
    "\n",
    "Como os elementos de $L$ estão a um passo a frente no método iterativo\n",
    "\n",
    "$Rx^{(k)} + Lx^{(k+1)} = b$\n",
    "\n",
    "Isolando $x^{(k+1)} = \\underset{C}{\\underbrace{-RL^{-1}}}x^{(k)} + \\underset{g}{\\underbrace{bL^{-1}}}$\n",
    "\n",
    "### Critérios de convergência\n",
    "\n",
    "O método de gauss-seidel converge para a solução $Ax=b$ para qualquer $x^{(0}$ se satisfazer uma das condições abaixo, caso não satisfaça não podemos deduzir nada:\n",
    "\n",
    "Muito semelhante ao critério de convergência de gauss-jacobi só que agora ao invés de chamar de $\\alpha$ chamamos de $\\beta$, o $\\beta_{1}$ é calculado da mesma forma que $\\alpha_{1}$ no método da linha, mas os restantes tem algumas mudanças, agora utilizamos os $\\beta_{i}$ já calculados para calcular o $\\beta$ dá próxima iteração.\n",
    "\n",
    "$\\beta = \\underset{1 \\leq i \\leq n}{max (\\beta_{i})<1}$, com $\\beta_{1}=\\frac{\\sum _{j=2}^{n}\\left | a_{1j} \\right |}{\\left | a_{11} \\right |}$ e com $\\beta_{i}=\\frac{\\sum _{j=1}^{i-1}\\left | a_{ij} \\right |\\beta_{j} +{\\sum _{j=i+1}^{n}\\left | a_{ij} \\right |}}{\\left | a_{ii} \\right |} $\n",
    "\n",
    "Quanto menor o $\\beta$, mais rápida será a convergência\n",
    "\n",
    "\n",
    "### Comparando\n",
    "\n",
    "Método de gauss jacobi paralelizavel, não depende das outras iterações\n",
    "Método de gauss seidel converge mais rápido\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seidel(A, b):\n",
    "    \n",
    "    # https://www3.nd.edu/~zxu2/acms40390F12/Lec-7.3.pdf\n",
    "    \n",
    "    n = len(b)\n",
    "    x = np.random.rand(n)\n",
    "    k = np.random.rand(n)\n",
    "    \n",
    "    for _ in range(1000):\n",
    "        for i in range(n):\n",
    "            sum_ = 0\n",
    "            for j in range(n):   \n",
    "                if i != j:\n",
    "                    sum_ += A[i, j] * x[j]\n",
    "            \n",
    "            x[i] = (b[i] - sum_)/A[i, i]\n",
    "        \n",
    "        if np.linalg.norm(x - k)/np.linalg.norm(x) < 1e-9:\n",
    "            break\n",
    "        else:\n",
    "            k = x.copy()\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[4,1,1], [1,2,-1], [1,-1,3]], dtype=np.float64)\n",
    "b = np.array([3,1,3/2], dtype=np.float64)\n",
    "\n",
    "# A = np.array([[3,-2,1], [1,-3,2], [-1,2,4]], dtype=np.float64)\n",
    "# b = np.array([3,1,3/2], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.solve(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.5, 0.5]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss = list(gaussian_elimination(A, b))\n",
    "solve_upper(gauss[0], gauss[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.5, 0.5000000000000001]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_cholesky(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobi(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seidel(A,b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
