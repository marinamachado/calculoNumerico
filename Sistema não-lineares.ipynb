{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas não-lineares\n",
    "\n",
    "\n",
    "## Zero de Funções\n",
    "\n",
    "Seja $f$ uma função contínua no intervalo $[a,b]$, queremos encontrar soluções para a equação não-linear:\n",
    "\n",
    "$$f(x) = 0$$\n",
    "\n",
    "Todos os valores que satisfazem essa equação acima são chamados de raízes ou zero da $f(x)$ e serão denotadas por $\\alpha$\n",
    "\n",
    "Vamos utilizar métodos iterativos para encontrar essas raízes, como é uma equação não-linear, não existe um número determinado de raízes.\n",
    "\n",
    "### Método iterativo\n",
    "\n",
    "Para resolver equações de grau 2 e 3 até existem métodos para resolução de equações mas quando o grau vai crescendo não temos uma forma analítica de resolver.\n",
    "\n",
    "Então precisa ser resolvido por um método iterativo, ou seja, dado um chute inicial $x_{0}$, gerar uma sequência de iterados que queremos que convirja para uma raiz da função. Assim não encontramos uma solução exata mas sim uma aproximação dela.\n",
    "\n",
    "**Para isso, precisamos:**\n",
    "\n",
    "1) Determinar um intervalo que contenha essa raiz $\\alpha$\n",
    "\n",
    "Pelo teorema do valor intermediário (TVI), se a função for contínua no intervalo $[(a,b)]$ e a $f(a)$ e $f(b)$, funções variadas no extremos, tem sinais diferentes então vai existir um $\\alpha$ no interior desse intervalo tal que $f(\\alpha)$ é 0, ou seja, Se $f \\in C([a,b]$ e $f(a)f(b)<0 \\Rightarrow \\exists \\alpha \\in (a,b)$.\n",
    "\n",
    "2) Analisar o gráfico para determinar esse intervalo que possui a raiz\n",
    "\n",
    "**Critério de parada**\n",
    "\n",
    "Critério de parada é o critério que ao ser atingido o processo iterativo é finalizado. Nesse caso $\\varepsilon$ e $\\tau$ são valores pré-definidos pelo usuário. Lembrando que os critérios abaixo podem ser combinados:\n",
    "\n",
    "1) Número de iterações, ao satisfazer a condição abaixo o processo é finalizado:\n",
    "\n",
    "$$k = k_{max} $$\n",
    "\n",
    "2) Erro absoluto, ao satisfazer a condição abaixo o processo é finalizado:\n",
    "\n",
    "$$\\left | x^{(k+1)} - x^{(k)}\\right | < \\varepsilon $$\n",
    "\n",
    "3) Erro relativo, mais robusto que o anterior, usado quando não quer levar em conta a ordem de grandeza, ao satisfazer a condição abaixo o processo é finalizado:\n",
    "\n",
    "$$\\frac{\\left | x^{(k+1)} - x^{(k)}\\right |}{x^{(k+1)}}<\\varepsilon $$\n",
    "\n",
    "4) Teste de resíduo, a precisão não é garantida, ao satisfazer a condição abaixo o processo é finalizado:\n",
    "\n",
    "$$\\left | f(x_{k})\\right | < \\tau  $$\n",
    "\n",
    "### Métoda da bisseção\n",
    "\n",
    "Esse método é baseado no TVI, pois sabemos que em determinado intervalo se os a função nos extremos tiverem sinais diferentes então com certeza a curva corta o eixo $x$.\n",
    "\n",
    "1) Ao plotar o gráfico observa o intervalo $[(a,b)]$ em que a função é continua e corta o eixo $x$ <br>\n",
    "2) Divide o intervalo ao meio, se o resultado for positivo: o valor do extremo em que a função é positiva recebe esse novo valor. Já se for negativo: o valor do extremo em que a função é negativa recebe esse novo valor. Sempre mantendo um dos valores do intervalo com sinais diferentes<br>\n",
    "3) Repete o segundo passo até atingir o critério de parada estabelecido<br>\n",
    "\n",
    "Para ilustrar melhor esse processo só observar o gif abaixo, mostra a curva $\\frac{1}{5}x^3 + 5$, onde selecionei o intervalo $(-10,0)$\n",
    "\n",
    "<img src=\"snl_imagens/bisseção.gif\" width=\"400\" align=\"left\" >\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "**Vantagens:**\n",
    "\n",
    "- Facil implementação\n",
    "- Seguro, se passa o intervalo certo\n",
    "- Sempre vai convergir para uma raiz\n",
    "- Requer apenas que seja continuo e mude de intervalo\n",
    "\n",
    "**Desvantagens:**\n",
    "\n",
    "- Lento \n",
    "- Difícil de generalizar para sistemas de equações nao lineares\n",
    "\n",
    "**Teorema que garante a convergência**\n",
    "\n",
    "Suponha $f \\in \\mathcal{C}([a,b])$ e $f(a)f(b)<0$. O método da bisseção gera uma\n",
    "sequência ${x_0, x_1, . . .}$ que se aproxima de uma raiz $\\alpha$ de $f$ com:\n",
    "$$\\left| x_{k} − \\alpha \\right| \\leq \\frac{b − a}{2^{k}}$$\n",
    "\n",
    "Como visto pelo TVI, sabemos que ao escolher o intervalo certo vai ter uma raiz nesse intervalo e o método da bisseção garante que sempre $f(a)$ e $f(b)$ terão sinais opostos, garantindo a aproximação da raiz. \n",
    "\n",
    "**Número de iterações**\n",
    "\n",
    "Usando esse teorema podemos estimar o número de iterações ($k$) que vamos precisar para determinada tolerância:\n",
    "\n",
    "Queremos que $x_{k} - \\alpha < \\varepsilon$, ou seja, a distância do valor encontrado para a raiz real seja do $\\varepsilon$ dado.\n",
    "\n",
    "- Utilizando o teorema, sabemos que $\\left | x_{k} - \\alpha \\right | < \\varepsilon \\leq \\frac{b − a}{2^{k}}$<br>\n",
    "- Supondo a igualdade e aplicando $\\log$ temos que $\\log_{2}\\varepsilon = \\log_{2}\\frac{b − a}{2^{k}}$. <br>\n",
    "- Utilizando a propriedade de $\\log$ temos que $\\log_{2}\\varepsilon = \\log_{2}(b − a) - \\log_{2}2^{k} \\Leftrightarrow \\log_{2}\\varepsilon = \\log_{2}(b − a) - k$. \n",
    "- Isolando $k$ conseguimos que a expressão que estima o número de iterações é $k = \\log_{2}(b − a) - \\log_{2}\\varepsilon$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bissecao(funcao,a,b,tol = 1e-6, kmax = 500):\n",
    "    \n",
    "    \"\"\" Encontra a raiz da função presente no intervalo dado \n",
    "            usando o Método da bisseção\n",
    "    \n",
    "    Args:\n",
    "        funcao: a funcao que queremos encontrar a raiz\n",
    "        a,b: intervalo \n",
    "        tol: tolerância desejada\n",
    "        kmax: número de iterações máximo\n",
    "    Retorno:\n",
    "        raiz aproximada x, numero de iterações necessárias\n",
    "    \"\"\"\n",
    "    \n",
    "    #calcula o valor médio\n",
    "    x = (a+b)/2\n",
    "    erro = np.inf\n",
    "    k = 0\n",
    "    \n",
    "    while(erro > tol and k < kmax):\n",
    "        \n",
    "        # se a e x tem sinais contrários\n",
    "        if(funcao(a)*funcao(x)<0):\n",
    "            b = x\n",
    "        # se a e x tem sinais diferentes\n",
    "        else:\n",
    "            a = x\n",
    "        \n",
    "        x0 = x\n",
    "        x = (a + b)/2 \n",
    "        erro = abs(x-x0)\n",
    "        k = k + 1\n",
    "    \n",
    "    return x,k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A raiz encontrada foi -2.924017310142517\n",
      "\n",
      "Número de iterações realizadas:23 \n",
      "Número de iterações estimada:23.253496664211536\n"
     ]
    }
   ],
   "source": [
    "# aplica o método da bisseção para encotrar a raiz do exemplo 0.2*xˆ5 + 5\n",
    "\n",
    "f = lambda x: (0.2)*x**3 + 5\n",
    "a = -10; b = 0; tol = 1e-6;\n",
    "\n",
    "x,k = bissecao(f,a,b)\n",
    "\n",
    "print(f'A raiz encontrada foi {x}\\n')\n",
    "\n",
    "# Calcula o número de iterações estimada\n",
    "k_estimado = math.log(b-a,2) - math.log(tol,2)\n",
    "\n",
    "print(f\"Número de iterações realizadas:{k} \\nNúmero de iterações estimada:{k_estimado}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de Ponto Fixo\n",
    "\n",
    "O problema de encontrar $f(x) = 0$ pode ser reescrito na forma  $g(x) = x $, ou seja, agora queremos encontrar o ponto fixo, isto é um ponto $\\alpha$ que satisfaz a equação  $g(\\alpha) = \\alpha$.\n",
    "\n",
    "Existem várias maneiras de escrever $g(x) = x$ a partir da $f(x)$:\n",
    "\n",
    "-  Podemos escrever da forma $g(x) = x - \\lambda f(x)$ onde $\\lambda$ é um real qualquer, já que se $x$ for $\\alpha$, e $f(\\alpha) = 0$ então chegamos em $g(x) = x$;<br>\n",
    "-  Podemos escrever da forma $g(x) = x - \\frac{f(x)}{f'(x)}$ se a $f(x)$ for derivável e não se anulo, ou seja, $f'(x)$ existe e $f'(x)\\neq 0$, a forma que utilizamos para o Método de Newton. Pode ser escrita pela mesma explicação da forma acima.\n",
    "\n",
    "### Método\n",
    "\n",
    "**Passo a passo**\n",
    "\n",
    "1) Dada um função real $f(x)$. Escolha uma função $g(x)$ tal que $f(x) = 0 \\Leftrightarrow x = g(x)$, ou seja, encontrar o zero da $f(x)$ é o mesmo que encontrar o ponto fixo da $g(x)$. Podemos escolher várias $g(x)$ possíveis mas dependendo da escolhida pode convergir mais rápido, mais devagar ou pode até nao convergir.\n",
    "\n",
    "2) Chuta um valor inicial $x_{0}$\n",
    "\n",
    "3) Começa o processo iterativo $x_{k+1} = g(x_{k})$, para $k = 1,2,3 ..$, então vamos utilizar o x anterior para calcular o novo valor.\n",
    "\n",
    "4) Quando $x_{k+1}$ satisfazer algum dos critérios de parada acaba o processo\n",
    "\n",
    "**Graficamente**\n",
    "\n",
    "Podemos demonstrar esse processo graficamente através do gif abaixo:\n",
    "\n",
    "<img style=\"float:left; padding-right:7px;\" src=\"snl_imagens/ponto_fixo.gif\" width=\"370\" align=\"left\" >\n",
    "<br><br>\n",
    "  1) Dado o $x_{0} = 5$, vai paralelamente ao eixo $x$ até a reta $y = x$, ou seja, dado o x qual o valor do $x_{k+1}$;<br><br>\n",
    "  \n",
    "  2) Depois vai paralelamente ao eixo y até nossa $g(x)$, ou seja, aplicar na nossa $g(x)$ esse novo valor de $x$;<br><br>\n",
    "  \n",
    "  3) Repete o processo e com o tempo irá convergindo para o ponto em que as dois gráficos se encontrarm que é justamente $ x = g(x)$\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "**Teorema**: Considere o Método do Ponto Fixo $x_{k+1} = g(x_{k}) k = 1,2,3 ..$.\n",
    "\n",
    "1) Se $g \\in \\mathcal{C}([a,b])$ e $g(x) \\in [a, b]$, para todo $x \\in [a, b]$, então existe um ponto fixo $\\alpha \\in [a, b]$ de $g(x)$ (Ou seja, para todo valor de $x$ que está no intervalo o $g(x)$ continua no intervalo.<br><br>\n",
    "2) Se, adicionalmente, a derivada $g'(x)$ existir e se houver uma constate ($\\rho  < 1)$, tal que: <br><br>$$\\left|g'(x)\\right| \\leq \\rho \\forall x \\in (a, b),$$ então o ponto fixo $\\alpha$ é único e a sequência gerada converge para $\\alpha$ independente da escolha do $x_{0} \\in [a,b]$.\n",
    "\n",
    "### Taxa de convergencia\n",
    "\n",
    "Para encontrar a taxa de convergência vamos usar o que vimos antes e o teorema anterior:\n",
    "\n",
    "- Supondo que $\\alpha$ é um ponto fixo do processo iterativo com $\\rho = \\left |g'(\\alpha)\\right|$ e $ 0 < \\rho < 1$\n",
    "\n",
    "- Aplicando a Fórmula de Taylo caso $x_0$ seja suficientemente perto de $\\alpha$ podemos dizer que $ x_k − \\alpha \\approx g'(\\alpha)(x_{k−1} − \\alpha)$\n",
    "\n",
    "- Aplicando módulo dos dois lados ficamos com $\\left |x_k − \\alpha\\right | \\approx \\left |g'(\\alpha)(x_{k−1} − \\alpha) \\right|$, como sabemos que $\\rho = \\left |g'(\\alpha)\\right|$, substituimos e ficamos com a expressão $\\left |x_k − \\alpha\\right | \\approx \\rho\\left |x_{k−1} − \\alpha\\right|$ (*)\n",
    "\n",
    "- Analogamente sabemos que  $\\left |x_{k−1} − \\alpha\\right| \\approx \\rho\\left |x_{k−2} − \\alpha\\right|$, então podemos substituir na expressão * , assim ficamos com $\\left |x_k − \\alpha\\right | \\approx \\rho\\rho\\left |x_{k−2} − \\alpha\\right|$ \n",
    "\n",
    "- Fazendo esse processo continuamente chegamos na equação final $\\left |x_k − \\alpha\\right | \\approx \\rho^{k}\\left |x_{0} − \\alpha\\right|$ \n",
    "\n",
    "- Para calcular quantas iterações levariam para reduzir o erro por um fator fixo de 10, dizemos que  \n",
    "$\\left |x_k − \\alpha\\right | \\approx  \\frac{1}{10}\\left|x_{0} − \\alpha\\right|$, ou seja, $\\rho^{k}$ é $10^{-1}$\n",
    "\n",
    "- Aplicando log chegamos que $k\\log(\\rho) = -1$, assim nossa taxa será $-\\log(\\rho)$ e o $k = \\frac{1}{\\text{taxa}}$, ou seja quanto maior a taxa menor a quantidade de iterações para reduzir o erro.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de Newton\n",
    "\n",
    "É um método de ponto fixo, e a ideia é linearizar a função em torno de $x_{k} \\approx \\alpha$, sendo $\\alpha$ minha raiz\n",
    "\n",
    "Para esse método $f(x)$:\n",
    "- Função que buscamos a raiz $\\alpha$ deve ser diferenciável.\n",
    "- A derivada deve ser simples de ser calculada comparada com a $f(x)$ se não teriam que ser feitas muitas regras da cadeia deixando o algoritmo custoso\n",
    "\n",
    "Expandindo pela Fórmula de Taylor $f(x)$ em torno do ponto $x_{k}$, conseguimos a expressão:<br><br>\n",
    "$$f(x) \\approx f(x_k) + f'(x_k)\\cdot(x-x_k)$$\n",
    "Substituindo $x$ por $\\alpha$, todos os termos $f(\\alpha)$ ficam 0 e ao isolar $\\alpha$ ficamos com a expressão:<br><br>\n",
    "$$\\alpha \\approx x_k - \\frac{f(x_k)}{f'(x_k)}$$\n",
    "\n",
    "Vamos utilizar essa expressão para ser justamente nossa $g(x)$ que falamos no método do ponto fixo, nota-se assim que $\\alpha = g(\\alpha)$, pois na expressão fica $g(\\alpha) = \\alpha + \\underset{0}{\\underbrace{\\frac{f(\\alpha)}{f'(\\alpha)}}}$.\n",
    "\n",
    "#### Processo iterativo\n",
    "\n",
    "Da mesma forma que o processo do ponto fixo o processo iterativo do método de newton segue a expressão abaixo com o objetivo de $x_{k+1}$ convergir para o nosso $\\alpha$:<br><br>\n",
    "$$ x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}, k = 0, 1, ...(*)$$ \n",
    "\n",
    "\n",
    "**Passo a passo:**\n",
    "<br><br>\n",
    "1) Chuta um $x_0$<br>\n",
    "2) Para k = 0, 1... calcula o $x_{k+1}$ seguindo o a expressão * <br>\n",
    "3) Ao atingir um critério de parada o processo acaba\n",
    "<br>\n",
    "\n",
    "**Graficamente** \n",
    "\n",
    "O processo é basicamente é pegar o ponto $x_0$, aplicar a $f(x)$ para ver o resultado, pega a derivada desse ponto que é a tangente a esse ponto e calcula a intersecção desse ponto no eixo $x$. O ponto onde foi a intersecção é o nosso próximo iterado $x_1$.\n",
    "Repetimos o processo aplicamos a $f(x)$ no ponto, calcula a derivada e vê onde a tangente corta o eixo, encontrando nosso $x_3$.\n",
    "\n",
    "<img src=\"snl_imagens/newton.png\" width=\"600\" align=\"left\" >\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "**Obs**:Para funcionar precisa escolher um bom $x_{0}$, dependendo da escolha pode não convergir\n",
    "\n",
    "**Vantagens**\n",
    "- Facil de implementar\n",
    "- A generalização para sistemas de equação é trivial\n",
    "- Convergencia rápida, converge quadraticamente\n",
    "\n",
    "**Desvantagens**\n",
    "\n",
    "- Dependendo do $x_0$ pode não convergir\n",
    "- Requer o cálculo da derivada\n",
    "- A função pode não ser diferenciavel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(funcao,dfuncao,x0,tol = 1e-6, kmax = 500,flag_print = 0):\n",
    "    \n",
    "    \"\"\" Encontra o ponto fixo da função usando o método de newton\n",
    "    \n",
    "    Args:\n",
    "        funcao: a funcao que queremos encontrar o ponto fixo\n",
    "        dfuncao: a derivada da funcao que queremos encontrar o ponto fixo\n",
    "        x0: chute inicial\n",
    "        tol: tolerância desejada\n",
    "        kmax: número de iterações máximo\n",
    "    Retorno:\n",
    "        ponto fixo aproximado x, numero de iterações necessárias\n",
    "    \"\"\"\n",
    "    \n",
    "    k = 0\n",
    "    x = x0 \n",
    "    erro = np.inf\n",
    "    \n",
    "    \n",
    "    while(k < kmax and erro > tol):\n",
    "        \n",
    "        dx = (funcao(x)/dfuncao(x))\n",
    "        x = x - dx\n",
    "        erro = abs(dx)\n",
    "        if(flag_print):\n",
    "            print(f'It {k}: {erro}')\n",
    "        k = k + 1\n",
    "        \n",
    "    if(k == kmax):\n",
    "        return np.nan, k\n",
    "    else:\n",
    "        return x, k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A raiz encontrada foi -2.924017738212866 com 11 iterações\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# O mesmo exemplo testado com o método da bisseção\n",
    "f = lambda x: (0.2)*x**3 + 5\n",
    "df = lambda x: (0.2)*3*x**2  \n",
    "\n",
    "x,k = newton(f,df,2)\n",
    "\n",
    "# O numéro de iterações foi menor\n",
    "print(f'A raiz encontrada foi {x} com {k} iterações\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método da Secante\n",
    "\n",
    "É justamente o método de newton, sem calcular a derivada pois vamos aproxima ela a diferença finita abaixo:<br><br>\n",
    "$$f'(x_k) \\approx\\frac{f(x_k) - f(x_{k-1})}{x_k - x_{k-1}}$$\n",
    "\n",
    "Depois só substituir na equação que utilizamos para o método de newton esse valor aproximado da derivada e ficamos com:<br><br>\n",
    "\n",
    "$$x_{k+1} = x_k - f(x_k)\\frac{x_k - x_{k-1}}{f(x_k) - f(x_{k-1})}$$\n",
    "\n",
    "**Vantagem comparado com o método de newton**\n",
    "- Não é preciso calcular a derivada, \n",
    "\n",
    "**Desvantagens comparado com o método de newton**\n",
    "\n",
    "- É preciso dois chutes iniciais\n",
    "- A convergência é um pouco mais lenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secante(funcao,x0,x1,tol = 1e-6, kmax = 500,flag_print = 0):\n",
    "    \n",
    "    \"\"\" Encontra o ponto fixo da função usando o método da secante\n",
    "    \n",
    "    Args:\n",
    "        funcao: a funcao que queremos encontrar o ponto fixo\n",
    "        x0: chute inicial 0 \n",
    "        x1: chute inicial 1\n",
    "        tol: tolerância desejada\n",
    "        kmax: número de iterações máximo\n",
    "    Retorno:\n",
    "        ponto fixo aproximado x, numero de iterações necessárias\n",
    "    \"\"\"\n",
    "    \n",
    "    k = 0\n",
    "    x = x1 \n",
    "    erro = np.inf\n",
    "    \n",
    "\n",
    "    while(k < kmax and erro > tol):\n",
    "        \n",
    "        #calcula aproximadamente a derivada\n",
    "        dfuncao = (funcao(x) - funcao(x0))/(x-x0)\n",
    "        dx = (funcao(x)/dfuncao)\n",
    "        \n",
    "        x0 = x;\n",
    "        x = x - dx\n",
    "       \n",
    "        erro = abs(dx)\n",
    "        \n",
    "        if(flag_print):\n",
    "            print(f'It {k}: {erro}')\n",
    "        k = k + 1\n",
    "       \n",
    "    # caso chegue no máximo de iterações e não convergir retorna nan\n",
    "    if(k == kmax):\n",
    "        return np.nan, k\n",
    "    else:\n",
    "        return x, k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A raiz encontrada foi -2.9240177382132133 com 11 iterações\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# O mesmo exemplo testado com o método da bisseção e em newton\n",
    "f = lambda x: (0.2)*x**3 + 5\n",
    "df = lambda x: (0.2)*3*x**2 \n",
    "\n",
    "x,k = secante(f,2,2.5)\n",
    "\n",
    "# Tem uma velocidade de convergencia próxima da de newton nesse caso a mesma\n",
    "print(f'A raiz encontrada foi {x} com {k} iterações\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergência dos métodos\n",
    "\n",
    "**Definição (ordem de convergência)**<br><br>\n",
    "Seja ${x_k}$ uma sequência obtida por um método iterativo tal que $x_k \\rightarrow x$, com $x \\neq\n",
    "x_k, \\forall k$. Se existirem um número $p \\geq 1$ e uma constante $c >$ 0 tais que:<br><br>\n",
    "$$\\lim_{k \\rightarrow \\infty} \\frac{(\\left|x_{k+1} − x \\right|}{(\\left|x_k − x \\right|)^p} = c,$$<br>\n",
    "então $p$ é a ordem de convergência desse método.\n",
    "\n",
    "**Analisando valores**<br>\n",
    "\n",
    "Quanto maior o $p$ maior a taxa de convergência\n",
    "\n",
    "1) Se $p = 1$ (e $c < 1$), o método possui convergência linear;<br>\n",
    "2) Se $p = 2$, o método possui convergência quadrática (Método de Newton), significa dobrar em cada iteração a precisão da raiz;<br>\n",
    "3) Se $p \\approx 1.6$, o metodo possui convergência super linear (Método da Secante).<br>\n",
    "\n",
    "\n",
    "#### Teoremas \n",
    "\n",
    "**Teorema (convergência do Método de Newton)**<br>\n",
    "Se $f \\in C^2 ([a, b])$ e existir $\\alpha \\in [a, b]$, tal que $f(\\alpha) = 0$ e $f'(\\alpha)\\neq 0$, então\n",
    "existe $\\delta > 0$ tal que a sequência ${x_k}$ gerada pelo Método de Newton converge quadraticamente para $\\alpha, \\forall x_0 \\in (\\alpha − \\delta, \\alpha + \\delta)$.<br>\n",
    "(Ou seja, para todo $x_0$ suficientemente perto da raiz a convergência quadrática irá acontecer, se estiverem na condições acima)\n",
    "\n",
    "**Teorema (convergência do Método da Secante)**<br>\n",
    "\n",
    "Se $f \\in C^2 ([a, b])$ e existir $\\alpha \\in [a, b]$, tal que $f(\\alpha) = 0$ e $f'(\\alpha)\\neq 0$, então\n",
    "existe $\\delta > 0$ tal que a sequência ${x_k}$ gerada pelo Método da Secante converge super linearmente para $\\alpha, \\forall x_0,x_1 \\in (\\alpha − \\delta, \\alpha + \\delta)$.<br>\n",
    "(Da mesma forma que o método acima mas agora precisaremos que os dois chutes iniciais estejam suficientemente perto da raiz para que a haja a convergência super linear).\n",
    "\n",
    "Por isso é muito importante sempre plotar a curva para encontrar bons chuter iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estudo de convergência do Método da Secante e de Newton\n",
    "\n",
    "Podemos observar nos exemplos abaixo a convergência de ambos os métodos\n",
    "\n",
    "**Newton**\n",
    "\n",
    "A convergência desse método é quadrático, ou seja, a cada iteração a precisão da raiz tende a ir duplicando, isso fica claro principalmente no final que o erro estava de $\\approx 1e-6$ e passa para $1e-12$\n",
    "\n",
    "**Secante**\n",
    "\n",
    "Como observado no exemplo abaixo, o erro diminui um pouco mais devagar que o Método de Newton, mas é o que é considerado convergência super linear, mais rápido que linear mas mais devagar que o quadrático. Isso fica claro ao final do processo já que a secante foi de $\\approx 1e-5$ para $1e-8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Método de Newton:\n",
      "\n",
      "It 0: 2.7499999999999996\n",
      "It 1: 14.56481481481483\n",
      "It 2: 5.069408267759515\n",
      "It 3: 3.335746510223698\n",
      "It 4: 2.1286758236592584\n",
      "It 5: 1.2290887127662153\n",
      "It 6: 0.523426274302797\n",
      "It 7: 0.1008903871889696\n",
      "It 8: 0.0035567707425204456\n",
      "It 9: 4.3299525785914126e-06\n",
      "It 10: 6.411768828393022e-12\n",
      "\n",
      "Método da Secante\n",
      "\n",
      "It 0: 2.6639344262295075\n",
      "It 1: 4.2603426994504225\n",
      "It 2: 3.0306314948024053\n",
      "It 3: 0.80532157794993\n",
      "It 4: 1.459720752721179\n",
      "It 5: 0.9127567154505744\n",
      "It 6: 0.13868040059350492\n",
      "It 7: 0.041930400040676025\n",
      "It 8: 0.002558615595277457\n",
      "It 9: 3.427747536433615e-05\n",
      "It 10: 2.9600885674169264e-08\n"
     ]
    }
   ],
   "source": [
    "print('Método de Newton:\\n')\n",
    "x,k = newton(f,df,2,flag_print=1)\n",
    "print('\\nMétodo da Secante\\n')\n",
    "x1,k1 = secante(f,2,2.5,flag_print=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação \n",
    "\n",
    "Nós podemos usar o método da bisseção, newton e secante para várias coisas pois em diversos problemas precisamos encontrar justamente os zeros da função.\n",
    "\n",
    "### Para calcular raizes (quadrática, cúbica,...)\n",
    "\n",
    "Por exemplo encontrar a raiz quadrada de 3 é justamente encontrar o zero da função $x^2 - 3$ como mostrado no gráfico abaixo, pra cúbica $x^3 - 3$ e assim por diante.\n",
    "\n",
    "<img src=\"snl_imagens/raiz.png\" width=\"310\" align=\"left\" >\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "Podemos então utilizar os métodos utilizados para calcular esses valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raiz(grau,x0,radicando,tipo):\n",
    "    \n",
    "    \"\"\" Encontra a raiz utilizando os metodos da bisseção, secante, newton\n",
    "    \n",
    "    Args:\n",
    "        funcao: a funcao que queremos encontrar o ponto fixo\n",
    "        x0: chute inicial \n",
    "        radicando: \n",
    "        tipo: qual método será utilizado para o processo\n",
    "    Retorno:\n",
    "        ponto fixo aproximado x, numero de iterações necessárias\n",
    "    \"\"\"\n",
    "    \n",
    "    if(grau<2):\n",
    "        print('Insira um grau que seja maior ou igual a dois')\n",
    "        return np.nan\n",
    "    \n",
    "    elif(radicando <2):\n",
    "        print('Insira um radicando que seja maior ou igual a dois')\n",
    "        return np.nan\n",
    "    \n",
    "    f = lambda x: x**(grau) - radicando\n",
    "    \n",
    "    if(tipo == 0):\n",
    "        \n",
    "        a = 0\n",
    "        b = max(radicando/grau,2) \n",
    "        resp, k = bissecao(f,a,b)\n",
    "        \n",
    "    elif(tipo == 1):\n",
    "\n",
    "        df = lambda x: (grau)*x**(grau-1)\n",
    "        resp, k = newton(f,df,x0)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        x1 = 1.2 * x0\n",
    "        resp, k = secante(f,x0,x1)\n",
    "\n",
    "    return resp, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Método da bisseção: (8.434326201677322, 27)\n",
      "Método de newton: (8.434326653017493, 5)\n",
      "Método da secante: (8.434326653019498, 6)\n"
     ]
    }
   ],
   "source": [
    "# Aqui dá para comparar melhor a convergência de cada uma, sendo o método de newton o mais rápido e o da bisseção\n",
    "print(f'Método da bisseção: {raiz(3,10,600,0)}')\n",
    "print(f'Método de newton: {raiz(3,10,600,1)}')\n",
    "print(f'Método da secante: {raiz(3,10,600,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equação de Kepler\n",
    "\n",
    "A equação de Kepler é uma equação transcendente, ou seja, não existe uma função elementar que resolva, porém existem métodos que resolvem por aproximações, por exemplo o método de newton.\n",
    "<br>\n",
    "$$M = E - e\\sin E,$$ <br><br> onde $M$ é a anomalia média, $E$ é a anomalia excêntrica e $e$ é a excentricidade orbital.<br> <br>Normalmente são dados $M$ e $e$, para encontrar o $E$.\n",
    "<br>\n",
    "\n",
    "\n",
    "#### Graficamente\n",
    "<!-- ![<](snl_imagens/keler.jpg =350x) -->\n",
    "<img style=\"float:left; padding-right:5px;\" src=\"snl_imagens/kepler.jpg\" width=\"360\" >\n",
    "<p style = \"line-height:30px;\" >\n",
    "• <b>Velocidade angular média</b> ($n$) velocidade angular para um corpo dar uma volta<br>\n",
    "• <b>Planeta</b> ($P$) simboliza o astro que está percorrendo a orbita<br>\n",
    "• <b>Anomalia média</b> ($M$) é o ângulo que seria percorrido pelo astro no intervalo de tempo se tivesse um movimento circular uniforme, no ponto y. $M = n \\cdot t$, onde t é o tempo percorrido<br>\n",
    "• <b>Excentricidade</b> ($e$) é o ângulo que representa o afastamento de uma órbita da forma circular.<br>\n",
    "• <b>Anomalia excentrica</b> ($E$) é o ângulo que é obtido ao traçar uma linha perpendicular ao eixo x que passa pelo ponto $P$ e alcança o círculo externo no ponto x <br>\n",
    "• <b>Anomalia verdadeira</b> ($\\theta$) é o ângulo entre o periastro (z) e a posição do astro, na órbita kepleriana. Pode ser obtido por $\\tan{\\left (\\frac{\\theta}{2}\\right)} = \\sqrt{\\frac{1+e}{1-e}}\\cdot \\tan{\\left (\\frac{E}{2}\\right)}$<br>\n",
    "• <b>Distância</b> (r) distância ao corpo central pode ser obtida por $r = \\frac{a\\cdot{(1 - e^2)}}{1 + e \\cdot \\cos{\\theta}},$ onde $a$ é o semi-eixo maior da órbita\n",
    "<br></p>\n",
    "\n",
    "#### Problemas\n",
    "1) Dado $e$ e  $M$ encontrar o valor da anomalia excentrica $E$\n",
    "\n",
    "2) Considere um foguete em uma órbita elíptica com semi-eixo maior $a = 25$ unidades e excentricidade $e = 0,6$. Suponha que o foguete esteja viajando com uma velocidade angular média de $\\frac{\\pi}{3600}$ radianos/segundo. Calcule a posição do foguete 10 minutos após a passagem de periastro.\n",
    "\n",
    "fonte : https://drive.google.com/file/d/130ri5h6PXaaUmLpNvUJCxQFqSaf-umpi/view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A anomalia excentrica é de aproximadamente 0.9220 e convergiu em 4 iterações\n"
     ]
    }
   ],
   "source": [
    "def solve_kepler(M,e):\n",
    "    \n",
    "    \"\"\" \n",
    "        Encontra anomalia excêntrica utilizando o método de newton e equação de kepler\n",
    "    \n",
    "    Args:\n",
    "       M: anomalia média\n",
    "       e: excentricidade\n",
    "    Retorno:\n",
    "        x: anomalia excêntrica\n",
    "    \"\"\"\n",
    "\n",
    "    # Nesse caso x é a anomalia excentrica\n",
    "    f = lambda x: M - x + (e*math.sin(x))\n",
    "    df =lambda x: -1 + e*math.cos(x)\n",
    "    \n",
    "    return newton(f,df,M)\n",
    "\n",
    "\n",
    "# Problema 1\n",
    "M = math.pi/6\n",
    "e = 0.5\n",
    "E,k = solve_kepler(M,e)\n",
    "\n",
    "print(f'A anomalia excentrica é de aproximadamente {E:.4f} e convergiu em {k} iterações')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O foguete está a uma distância de 17.426 unidades do planeta a uma anomalia verdadeira de 1.7076 radianos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17.426040563036764, 1.707612569003758)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rocket_position(e,n,a,t):\n",
    "    \n",
    "    \"\"\" \n",
    "        Encontra distancia do foguete e anomalia verdadeira, utilizando a equação de kepler \n",
    "            e o método de newton\n",
    "    \n",
    "    Args:\n",
    "       n: velocidade angular média\n",
    "       e: excentricidade\n",
    "       a: semi-eixo maior da órbita\n",
    "       t: tempo percorrido\n",
    "       \n",
    "    Retorno:\n",
    "        r: distancia \n",
    "        theta: anomalia verdadeira\n",
    "    \"\"\"\n",
    "\n",
    "    # passa o tempo para segundos\n",
    "    t = t * 60\n",
    "\n",
    "    M = n*t\n",
    "\n",
    "    E,k = solve_kepler(M,e)\n",
    "    \n",
    "    # calcula theta em radianos\n",
    "    theta = 2*(math.atan((math.sqrt((1+e)/(1-e)))*(math.tan(E/2))))\n",
    "\n",
    "    r = (a*(1-e**2))/(1+e*math.cos(theta))\n",
    "    \n",
    "    print(f'O foguete está a uma distância de {r:.3f} unidades do planeta a uma anomalia verdadeira de {theta:.4f} radianos')\n",
    "    \n",
    "    return r,theta\n",
    "\n",
    "# Problema 2\n",
    "e = 0.6\n",
    "n = math.pi/3600\n",
    "a = 25\n",
    "t = 10  \n",
    "\n",
    "rocket_position(e,n,a,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistemas Não-Lineares\n",
    "\n",
    "Queremos resolver sistemas não-lineares com tamanhos variáveis e para isso vamos utilizar o Método de Newton citado anteriormente.\n",
    "\n",
    "Podemos expressar um sistema não linear abaixo,\n",
    "\n",
    "$\\left\\{\\begin{matrix}f_1(x_1,x_2,x_3,...,x_n)=0 \n",
    "\\\\ f_2(x_1,x_2,x_3,...,x_n) = 0 \n",
    "\\\\ \\vdots\n",
    "\\\\ f_n(x_1,x_2,x_3,...,x_n) = 0\n",
    "\\end{matrix}\\right.$\n",
    "<br><br>na forma vetorial:\n",
    "$f(x) = \\bar{0} $ onde $f(x) e x $ são vetores de $n$ cordenadas<br><br>\n",
    "\n",
    "### Exemplo de resolução de sistemas não lineares\n",
    "\n",
    "Por exemplo:\n",
    "\n",
    "$f_1(x_1, x_2) = x_1 -x_2^{3}$<br><br>\n",
    "$f_2(x_1, x_2) = \\frac{x_1^{2}}{2} + \\frac{x_2^{2}}{4} -1 $\n",
    "\n",
    "É justamente calcular os pontos onde a parábola intersecta a elipse<br>\n",
    "<img src=\"snl_imagens/elipse.png\" width=\"370\" align=\"left\" >\n",
    "<br><br><br><br><br><br><br><br><br><br><br>\n",
    "Para resolver esses problemas de maneira iterativa vamos generalizar o método de newton para nosso sistema.\n",
    "No método de newton chutávamos um $x_0$ pertencente aos reais suficientemente próximo da raiz e a cada etapa tentava se aproximar maiz da raiz $\\alpha$. A ideia é similar mas agora o chute inicial é um vetor e a cada etapa ir na direção do vetor solução.\n",
    " Então agora vamos linearizar o problema como fizemos anteriormente utilizando a Serie de Taylor agora para funções vetoriais:\n",
    "\n",
    "**Teorema(Série de Taylor para funções vetoriais):**\n",
    "\n",
    "Suponha que $f : \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{m}$ seja suficientemente diferenciável. Logo, para um\n",
    "vetor direção $v = (v_1, v_2, ... , v_n)$, a expansão de Taylor para cada função $f_i$ para cada coordenada $x_j$ vale:\n",
    "$$f(x + v) = f(x) + J(x)v + \\mathcal{O}\\left \\| v\\right \\|^{2}$$ onde $J(x)$ é a matriz jacobiana e o erro é de ordem 2:\n",
    "\n",
    "$J(x) = \\begin{bmatrix}\n",
    "\\frac{\\delta f_1}{\\delta x_1}&  \\frac{\\delta f_1}{\\delta x_2}& \\cdots &\\frac{\\delta f_1}{\\delta x_n} \\\\\\frac{\\delta f_2}{\\delta x_1}&  \\frac{\\delta f_2}{\\delta x_2}& \\cdots &\\frac{\\delta f_2}{\\delta x_n} \\\\ \n",
    "\\vdots&  \\vdots&  \\ddots& \\vdots\\\\ \n",
    "\\frac{\\delta f_m}{\\delta x_1}&  \\frac{\\delta f_m}{\\delta x_2}& \\cdots &\\frac{\\delta f_m}{\\delta x_n}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "A Jacobiana é formada pela derivadas parciais de cada $f_{i}$ por cada $x_{j}$.\n",
    "\n",
    "### Extensão do Método de Newton\n",
    "\n",
    "1) Dado um vetor como chute inicial $x_0$, vamos gerar uma sequência de $x_0,x_1,...$ onde o $x_{k+1}$ é obtido pelo iterado anterior linearizando $f(x) = \\bar{0}$<br>\n",
    "2) Por Taylor, seja $\\alpha = x_k +v$, onde $\\alpha$ é raiz da função, para um $v$ suficientemente pequeno temos:\n",
    "\n",
    "$$f(\\alpha) = f(x_k + v) \\approx f(x_k) + J(x_k)v$$\n",
    "\n",
    "3) Determinar o vetor $v$, sabemos que $f(\\alpha) = \\bar{0}$ e podemos, como mostrado acima, dizer que $f(\\alpha)\\approx f(x_k) + J(x_k)v$ com $\\alpha = x_k + v$ com esses resultados podemos aproximar;\n",
    "\n",
    "$$f(x_k) + J(x_k)v_k = \\bar{0} \\Leftrightarrow J(x_k)v_k = - f(x_k),$$\n",
    "\n",
    "então para encontrar o $v$ basta resolver o sistema linear  $J(x_k)v_k = - f(x_k)$.\n",
    "\n",
    "4) Nosso processo iterativo seria como o MPF $x_{k+1} = x_k + v_k $ Para $k = 0,1,2,...$\n",
    "- Para isso basta resolver o sistema linear $J(x_k)v_k = - f(x_k)$ \n",
    "- Substituir na fórmula $x_{k+1} = x_k + v_k $ o $v_k$ encontrado.\n",
    "- Repetir o processo até atingir um critério de parada\n",
    "\n",
    "**Obs:** Método ainda muito custoso mas é simples de implementar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sistemas_newton(funcao,jac,x,tol = 1e-6, kmax = 10000):\n",
    "    \"\"\" \n",
    "        Encontra o resultado do sistema não linear utilizando o método de newton\n",
    "    \n",
    "    Args:\n",
    "       funcao: vetor com as funções\n",
    "       jac: vetor com as jacobianas de cada\n",
    "       x: vetor do chute inicial\n",
    "       tol: tolerância\n",
    "       kmax: número máximo de iterações \n",
    "       \n",
    "    Retorno:\n",
    "        x: vetor resultado\n",
    "        k: número de iterações necessárias\n",
    "        nan: se k atingir o kmax\n",
    "    \"\"\"\n",
    "    \n",
    "    k=0\n",
    "    erro = np.inf\n",
    "    \n",
    "    while(k<kmax and erro>tol):\n",
    "        \n",
    "        # resolve o sistema linear para encontrar v\n",
    "        v = np.linalg.solve(jac(x),funcao(x))\n",
    "        x = x - v\n",
    "        erro = np.linalg.norm(v)\n",
    "        k = k+1\n",
    "    \n",
    "    if(k == kmax):\n",
    "        return np.nan, k\n",
    "    else:\n",
    "        return x, k\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação de newton para sistemas não lineares\n",
    "\n",
    "Podemos utilizar o método de newton para calcular onde duas ou mais curvas se intersectam. Esse ponto é justamente a solução do sistema.\n",
    "\n",
    "Por exemplo vamos resolver através do método de newton onde a curvas citadas anteriormente se interseção. Sempre importante plotar o gráfico para dar bons chutes iniciais\n",
    "\n",
    "<img src=\"snl_imagens/elipse.png\" width=\"370\" align=\"left\" >\n",
    "<br><br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "$f_1(x_1, x_2) = x_1 -x_2^{3}$<br><br>\n",
    "$f_2(x_1, x_2) = \\frac{x_1^{2}}{2} + \\frac{x_2^{2}}{4} -1 $\n",
    "\n",
    "Os resultados podem ser comparados com a da imagem acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As curvas de intersectam no ponto [1.19829589 1.06215531] e no ponto [-1.19829589 -1.06215531]\n"
     ]
    }
   ],
   "source": [
    "# função de cada curva\n",
    "f1 = lambda x: x[0] -  x[1]**3\n",
    "f2 = lambda x: (x[0]**2)/2 +(x[1]**2)/4 -1\n",
    "F = lambda x: np.array([f1(x),f2(x)])\n",
    "\n",
    "# Definindo a jacobiana \n",
    "jac11 = lambda x: 1;\n",
    "jac12 = lambda x: -3*x[1]**2;\n",
    "jac21 = lambda x: x[0];\n",
    "jac22 = lambda x: x[1]/2;\n",
    "Jac = lambda x: np.array([[jac11(x),jac12(x)],[jac21(x),jac22(x)]])\n",
    "\n",
    "\n",
    "# Para encontrar o primeiro ponto  \n",
    "# chute inicial\n",
    "x0 = [1.5,1.5];\n",
    "(x,k) = sistemas_newton(F,Jac,x0)\n",
    "\n",
    "# Para encontrar o segundo ponto  \n",
    "# chute inicial\n",
    "x1 = [-1.5,-1.5];\n",
    "(x1,k1) = sistemas_newton(F,Jac,x1)\n",
    "\n",
    "print(f'As curvas de intersectam no ponto {x} e no ponto {x1}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
